{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notbook is using device: cuda\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.ROOT_DATA_DIR=\"FashionMNISTDir\"\n",
    "        self.EPOCH =10\n",
    "        self.LEARNING_RATE=0.01\n",
    "        self.IMAGE_SIZE=(28,28)\n",
    "        self.BATCH_SIZE=32\n",
    "        self.DEVICE=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"This notbook is using device: {self.DEVICE}\")\n",
    "        self.SEED=2022\n",
    "\n",
    "config=Config()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=datasets.FashionMNIST(\n",
    "    root=config.ROOT_DATA_DIR,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    \n",
    ")\n",
    "\n",
    "test_data=datasets.FashionMNIST(\n",
    "    root=config.ROOT_DATA_DIR,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "given_label_map=train_data.class_to_idx\n",
    "given_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map={val:key for key, val in given_label_map.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'T-shirt/top',\n",
       " 1: 'Trouser',\n",
       " 2: 'Pullover',\n",
       " 3: 'Dress',\n",
       " 4: 'Coat',\n",
       " 5: 'Sandal',\n",
       " 6: 'Shirt',\n",
       " 7: 'Sneaker',\n",
       " 8: 'Bag',\n",
       " 9: 'Ankle boot'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualize one of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd=1\n",
    "def view_sample_img(data,rnd,label_map):\n",
    "    plt.imshow(train_data.data[rnd],cmap='gray')\n",
    "    plt.title(f\"data_label: {label_map[train_data.targets[rnd].item()]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "view_sample_img(train_data,7,label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader=DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=True\n",
    "    \n",
    ")\n",
    "\n",
    "test_data_loader=DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for images,labels in train_data_loader:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([28, 28]), torch.Size([1, 1, 28, 28]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].squeeze().shape, images[0].unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x206007da1c8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].squeeze(),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,input_channel,output_channel):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv_pool_01=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channel,\n",
    "            out_channels=8,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=0),\n",
    "\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2\n",
    "            )\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.conv_pool_02=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=0),\n",
    "\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2\n",
    "            )\n",
    "\n",
    "            )\n",
    "        self.Flatten=nn.Flatten()\n",
    "        self.FC_01=nn.Linear(in_features=16*4*4, out_features=128)\n",
    "        self.FC_02=nn.Linear(in_features=128, out_features=64)\n",
    "        self.FC_03=nn.Linear(in_features=64, out_features=output_channel)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv_pool_01(x)\n",
    "        x = self.conv_pool_02(x)\n",
    "        x = self.Flatten(x)\n",
    "        x = self.FC_01(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.FC_02(x)\n",
    "        x = F.relu(x)    \n",
    "        x = self.FC_03(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv_pool_01): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_pool_02): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (FC_01): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (FC_02): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (FC_03): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=CNN(1,10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_pool_01): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_pool_02): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (FC_01): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (FC_02): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (FC_03): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the no. of trainable parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e3566_\">\n",
       "  <caption>Total parameters are: {'trainable': 45226, 'non_trainable': 0}</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >modules</th>\n",
       "      <th class=\"col_heading level0 col1\" >Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e3566_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e3566_row0_col0\" class=\"data row0 col0\" >conv_pool_01.0.weight</td>\n",
       "      <td id=\"T_e3566_row0_col1\" class=\"data row0 col1\" >200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3566_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e3566_row1_col0\" class=\"data row1 col0\" >conv_pool_01.0.bias</td>\n",
       "      <td id=\"T_e3566_row1_col1\" class=\"data row1 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3566_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e3566_row2_col0\" class=\"data row2 col0\" >conv_pool_02.0.weight</td>\n",
       "      <td id=\"T_e3566_row2_col1\" class=\"data row2 col1\" >3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3566_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e3566_row3_col0\" class=\"data row3 col0\" >conv_pool_02.0.bias</td>\n",
       "      <td id=\"T_e3566_row3_col1\" class=\"data row3 col1\" >16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3566_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e3566_row4_col0\" class=\"data row4 col0\" >FC_01.weight</td>\n",
       "      <td id=\"T_e3566_row4_col1\" class=\"data row4 col1\" >32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3566_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e3566_row5_col0\" class=\"data row5 col0\" >FC_01.bias</td>\n",
       "      <td id=\"T_e3566_row5_col1\" class=\"data row5 col1\" >128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3566_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e3566_row6_col0\" class=\"data row6 col0\" >FC_02.weight</td>\n",
       "      <td id=\"T_e3566_row6_col1\" class=\"data row6 col1\" >8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3566_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e3566_row7_col0\" class=\"data row7 col0\" >FC_02.bias</td>\n",
       "      <td id=\"T_e3566_row7_col1\" class=\"data row7 col1\" >64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3566_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e3566_row8_col0\" class=\"data row8 col0\" >FC_03.weight</td>\n",
       "      <td id=\"T_e3566_row8_col1\" class=\"data row8 col1\" >640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3566_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e3566_row9_col0\" class=\"data row9 col0\" >FC_03.bias</td>\n",
       "      <td id=\"T_e3566_row9_col1\" class=\"data row9 col1\" >10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2060080e208>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def count_params(model):\n",
    "    model_params={\"modules\": list(),\"Parameters\": list()}\n",
    "    total={\"trainable\": 0,\"non_trainable\":0}\n",
    "    for name , parameters in model.named_parameters():\n",
    "        param=parameters.numel()\n",
    "        if not parameters.requires_grad:\n",
    "            total[\"non_trainable\"]+=param\n",
    "            continue\n",
    "        model_params['modules'].append(name)\n",
    "        model_params['Parameters'].append(param)\n",
    "        total['trainable']+=param\n",
    "    df=pd.DataFrame(model_params)\n",
    "    df=df.style.set_caption(f\"Total parameters are: {total}\")\n",
    "    return df\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss() #loss function\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=config.LEARNING_RATE) #optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#steps per epoch:\n",
    "len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/1875 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.functional' has no attribute 'relu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21756\\411923187.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;31m#doing th forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\DataScience\\ineuron\\dl\\FSDS-pytorch-CNN\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21756\\601588446.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFC_01\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFC_02\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.functional' has no attribute 'relu'"
     ]
    }
   ],
   "source": [
    "for epoch in range(config.EPOCH):\n",
    "    with tqdm(train_data_loader) as tqdm_epoch:\n",
    "        for images,labels in tqdm_epoch:\n",
    "            tqdm_epoch.set_description(f'Epoch {epoch+1}/{config.EPOCH}')\n",
    "            # put the images on device\n",
    "            images=images.to(config.DEVICE)\n",
    "            labels=labels.to(config.DEVICE)\n",
    "\n",
    "            \n",
    "            #doing th forward pass\n",
    "            output=model(images)\n",
    "            loss=criterion(output,labels)\n",
    "\n",
    "            #backward propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step() #updating weights\n",
    "\n",
    "            tqdm_epoch.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f65fd47d78e5bd644a88cb5574e1db8ce233601f2d427979b1d495ac7be1cec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
